@article{ alaniz2021giants,
    author = {Alaniz, Alberto J and Carvajal, Mario A and Vergara, Pablo M},
    title = {Giants are coming? {P}redicting the potential spread and impacts of the giant {A}sian hornet ({V}espa mandarinia, {H}ymenoptera:{V}espidae) in the {USA}},
    journal = {Pest Management Science},
    volume = {77},
    number = {1},
    pages = {104-112},
    doi = {https://doi.org/10.1002/ps.6063},
    url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/ps.6063},
    eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/ps.6063},
    abstract = {Abstract BACKGOUND Biological invasions are a global concern in agriculture, food production and biodiversity. Among the invasive species, some hornets are known to have serious effects on honey bees, as found during the invasion of Vespa velutina in Europe. The recent findings of Vespa mandarinia individuals in Washington state in the west coast of the USA have raised alarm in the whole country. Here we estimate the potential spread of V. mandarinia in the USA, analyzing its potential impacts on honey bee colonies, economic losses in the honey bee industry and bee-pollinated croplands. RESULTS We found that V. mandarinia could colonize Washington and Oregon states in the west coast and a significant proportion of the east coast. If this species spread across the country, it could threaten 95 216 ± 5551 honey bee colonies, threatening an estimated income of US\$11.9 and 101.8 million for hive derived products and bee-pollinated crops production, respectively, while colonizing 60 837.8 km2 of bee-pollinated croplands. CONCLUSION Our results suggest that V. mandarinia will have serious effects in the USA, raising the need for prompt monitoring actions and planning at different administrative levels to avoid its potential spread.},
    year = {2021}
}

@article{ matsuura1973bionomic,
    author  = {MATSUURA, Makoto and SAKAGAMI, Shôichi F.},
    title = {A Bionomic Sketch of the Giant Hornet, {V}espa mandarinia, a Serious Pest for {J}apanese Apiculture (With 12 Text-figures and 5 Tables)},
    journal = {Journal of the Faculty of Science, Hokkaido University},
    year  = {1973},
    month  = {oct},
    volume = {19},
    number = {1},
    pages  = {125--162},
    url = {http://hdl.handle.net/2115/27557}
}

@article{ nunez2021geo,
    author = {Nuñez-Penichet C and Osorio-Olvera L and Gonzalez VH and Cobos ME and Jiménez L and DeRaad DA and Alkishe A and Contreras-Díaz RG and Nava-Bolaños A and Utsumi K and Ashraf U and Adeboje A and Peterson AT and Soberon J},
    year = {2021},
    title = {Geographic potential of the world’s largest hornet, Vespa mandarinia Smith (Hymenoptera: Vespidae), worldwide and particularly in North America},
    journal = {PeerJ},
    volume = {9},
    pages = {e10690},
    url = {https://doi.org/10.7717/peerj.10690}
}
@article{ STDBScan,
    author  = {Derya Birant, Alp Kut},
    title = {ST-DBSCAN: An algorithm for clustering spatial–temporal data},
    journal = {Data \& Knowledge Engineering},
    year  = {2007},
    volume = {60},
    number = {1},
    pages  = {208-221},
    url = {https://doi.org/10.1016/j.datak.2006.01.013},
    abstract = {This paper presents a new density-based clustering algorithm, ST-DBSCAN, which is based on DBSCAN. We propose three marginal extensions to DBSCAN related with the identification of (i) core objects, (ii) noise objects, and (iii) adjacent clusters. In contrast to the existing density-based clustering algorithms, our algorithm has the ability of discovering clusters according to non-spatial, spatial and temporal values of the objects. In this paper, we also present a spatial–temporal data warehouse system designed for storing and clustering a wide range of spatial–temporal data. We show an implementation of our algorithm by using this data warehouse and present the data mining results.}
}

@article{ resnet,
	author = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
	title = {Deep Residual Learning for Image Recognition},
	journal = {arXiv preprint arXiv:1512.03385},
	year = {2015}
}

@inproceedings{ imagenet_cvpr09,
    AUTHOR = {Deng, J. and Dong, W. and Socher, R. and Li, L.-J. and Li, K. and Fei-Fei, L.},
    TITLE = {{ImageNet: A Large-Scale Hierarchical Image Database}},
    BOOKTITLE = {CVPR09},
    YEAR = {2009},
    BIBSOURCE = {http://www.image-net.org/papers/imagenet_cvpr09.bib}
}

@inproceedings{ alexnet,
    author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
    title = {ImageNet Classification with Deep Convolutional Neural Networks},
    year = {2012},
    publisher = {Curran Associates Inc.},
    address = {Red Hook, NY, USA},
    abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5 and 17.0 which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully-connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overriding in the fully-connected layers we employed a recently-developed regularization method called "dropout" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3, compared to 26.2 achieved by the second-best entry.},
    booktitle = {Proceedings of the 25th International Conference on Neural Information Processing Systems - Volume 1},
    pages = {1097–1105},
    numpages = {9},
    location = {Lake Tahoe, Nevada},
    series = {NIPS'12}
}

@article{ transferlearning,
	author = {Weiss, Karl and Khoshgoftaar, Taghi M. and Wang, DingDing},
	title = {A survey of transfer learning},
	journal = {Journal of Big Data},
	year = {2016},
	volume = {3},
	number = {1},
	pages = {9},
	url = {https://doi.org/10.1186/s40537-016-0043-6},
    abstract = {Machine learning and data mining techniques have been used in numerous real-world applications. An assumption of traditional machine learning methodologies is the training data and testing data are taken from the same domain, such that the input feature space and data distribution characteristics are the same. However, in some real-world machine learning scenarios, this assumption does not hold. There are cases where training data is expensive or difficult to collect. Therefore, there is a need to create high-performance learners trained with more easily obtained data from different domains. This methodology is referred to as transfer learning. This survey paper formally defines transfer learning, presents information on current solutions, and reviews applications applied to transfer learning. Lastly, there is information listed on software downloads for various transfer learning solutions and a discussion of possible future research work. The transfer learning solutions surveyed are independent of data size and can be applied to big data environments.}
}

@misc{ AGH,
    author = {Michael J. Skvarla},
    title = {Asian Giant Hornets},
    note = {\texttt{\small https://extension.psu.edu/asian-giant-hornets}, accessed on February 8, 2021}
}

@Inbook{ liu2011intro,
    author = {Liu, Sifeng and Lin, Yi},
    title = {Introduction to Grey Systems Theory},
    bookTitle = {Grey Systems: Theory and Applications},
    year = {2011},
    publisher = {Springer Berlin Heidelberg},
    address = {Berlin, Heidelberg},
    pages = {1--18},
    abstract = {On the basis of dividing the spectrum of scientific and technological endeavors into finer sections, the overall development of modern science has shown the tendency of synthesis at a higher level. This higher level synthesis has caused the appearance of the various studies of systems science with their specific methodological and epistemological significance. Systems science reveals the much deeper and more intrinsic connections and interlockings of objects and events and has greatly enriched the overall progress of science and technology. Many of the historically difficult problems in different scientific fields have been resolved successfully along with the appearance of systems science and its specific branches. And because of the emergence of various new areas in systems science, our understanding of nature and the laws that govern objective evolutions has been gradually deepened. At the end of the 1940s, there appeared systems theory, information theory, cybernetics. Toward the end of 1960s and the start of 1970s, there appeared the theory of dissipative structures, synergics, catastrophe, and bifurcations. During the middle and toward the end of the 1970s, there appeared one by one such new transfield and interfiled theories of systems science as the ultracircular theory, dynamic systems, pansystems, etc.},
    isbn = {978-3-642-16158-2},
    doi = {10.1007/978-3-642-16158-2_1},
    url = {https://doi.org/10.1007/978-3-642-16158-2_1}
}

@article{ julong1989intro,
  title={Introduction to grey system theory},
  author={Julong, Deng},
  journal={The Journal of grey system},
  volume={1},
  number={1},
  pages={1--24},
  year={1989},
  publisher={Citeseer}
}

@article{ peterson2012species,
  title={Species Distribution Modeling and Ecological Niche Modeling: Getting the Concepts Right},
  author={A. Peterson and Jorge Sober{\'o}n},
  journal={Natureza \& Conservacao},
  year={2012},
  volume={10},
  pages={102-107}
}

@article{ elith2010art,
    author = {Elith, Jane and Kearney, Michael and Phillips, Steven},
    title = {The art of modelling range-shifting species},
    journal = {Methods in Ecology and Evolution},
    volume = {1},
    number = {4},
    pages = {330-342},
    keywords = {cane toad, changing correlations, climate change, extrapolation, invasive species, niche models, novel environments, species distribution models},
    doi = {https://doi.org/10.1111/j.2041-210X.2010.00036.x},
    url = {https://besjournals.onlinelibrary.wiley.com/doi/abs/10.1111/j.2041-210X.2010.00036.x},
    eprint = {https://besjournals.onlinelibrary.wiley.com/doi/pdf/10.1111/j.2041-210X.2010.00036.x},
    abstract = {Summary 1. Species are shifting their ranges at an unprecedented rate through human transportation and environmental change. Correlative species distribution models (SDMs) are frequently applied for predicting potential future distributions of range-shifting species, despite these models’ assumptions that species are at equilibrium with the environments used to train (fit) the models, and that the training data are representative of conditions to which the models are predicted. Here we explore modelling approaches that aim to minimize extrapolation errors and assess predictions against prior biological knowledge. Our aim was to promote methods appropriate to range-shifting species. 2. We use an invasive species, the cane toad in Australia, as an example, predicting potential distributions under both current and climate change scenarios. We use four SDM methods, and trial weighting schemes and choice of background samples appropriate for species in a state of spread. We also test two methods for including information from a mechanistic model. Throughout, we explore graphical techniques for understanding model behaviour and reliability, including the extent of extrapolation. 3. Predictions varied with modelling method and data treatment, particularly with regard to the use and treatment of absence data. Models that performed similarly under current climatic conditions deviated widely when transferred to a novel climatic scenario. 4. The results highlight problems with using SDMs for extrapolation, and demonstrate the need for methods and tools to understand models and predictions. We have made progress in this direction and have implemented exploratory techniques as new options in the free modelling software, MaxEnt. Our results also show that deliberately controlling the fit of models and integrating information from mechanistic models can enhance the reliability of correlative predictions of species in non-equilibrium and novel settings. 5. Implications. The biodiversity of many regions in the world is experiencing novel threats created by species invasions and climate change. Predictions of future species distributions are required for management, but there are acknowledged problems with many current methods, and relatively few advances in techniques for understanding or overcoming these. The methods presented in this manuscript and made accessible in MaxEnt provide a forward step.},
    year = {2010}
}
@Inbook{tfidf,
editor="Sammut, Claude
and Webb, Geoffrey I.",
title="TF--IDF",
bookTitle="Encyclopedia of Machine Learning",
year="2010",
publisher="Springer US",
address="Boston, MA",
pages="986--987",
isbn="978-0-387-30164-8",
doi="10.1007/978-0-387-30164-8_832",
url="https://doi.org/10.1007/978-0-387-30164-8_832"
}
@article{lda,
author = {Blei, David M. and Ng, Andrew Y. and Jordan, Michael I.},
title = {Latent Dirichlet Allocation},
year = {2003},
issue_date = {3/1/2003},
publisher = {JMLR.org},
volume = {3},
number = {null},
issn = {1532-4435},
abstract = {We describe latent Dirichlet allocation (LDA), a generative probabilistic model for collections of discrete data such as text corpora. LDA is a three-level hierarchical Bayesian model, in which each item of a collection is modeled as a finite mixture over an underlying set of topics. Each topic is, in turn, modeled as an infinite mixture over an underlying set of topic probabilities. In the context of text modeling, the topic probabilities provide an explicit representation of a document. We present efficient approximate inference techniques based on variational methods and an EM algorithm for empirical Bayes parameter estimation. We report results in document modeling, text classification, and collaborative filtering, comparing to a mixture of unigrams model and the probabilistic LSI model.},
journal = {J. Mach. Learn. Res.},
month = mar,
pages = {993–1022},
numpages = {30}
}
@Inbook{naivebayes,
author="Webb, Geoffrey I.",
editor="Sammut, Claude
and Webb, Geoffrey I.",
title="Na{\"i}ve Bayes",
bookTitle="Encyclopedia of Machine Learning",
year="2010",
publisher="Springer US",
address="Boston, MA",
pages="713--714",
isbn="978-0-387-30164-8",
doi="10.1007/978-0-387-30164-8_576",
url="https://doi.org/10.1007/978-0-387-30164-8_576"
}